{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to calculate RSI\n",
    "def calculate_rsi(data, window=14):\n",
    "    delta = data['Close'].diff(1)\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return rsi\n",
    "\n",
    "# Function to calculate MACD\n",
    "def calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "    short_ema = data['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "    long_ema = data['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "    \n",
    "    macd = short_ema - long_ema\n",
    "    signal_line = macd.ewm(span=signal_window, adjust=False).mean()\n",
    "    \n",
    "    return macd, signal_line\n",
    "\n",
    "def fetch_and_analyze_etf_data(ticker):\n",
    "    asset = yf.Ticker(ticker)\n",
    "    end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.today() - timedelta(days=730)).strftime('%Y-%m-%d')\n",
    "    data = asset.history(start=start_date, end=end_date)\n",
    "    data.reset_index(inplace=True)\n",
    "    data['rsi'] = calculate_rsi(data)\n",
    "    data['macd'], data['signal_line'] = calculate_macd(data)\n",
    "    return data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'rsi', 'macd', 'signal_line']]\n",
    "\n",
    "etf_data = fetch_and_analyze_etf_data(\"EWJ\")\n",
    "etf_data.to_csv(\"etf_momentum_analysis.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_index_data(tickers):\n",
    "    all_data = []\n",
    "    for ticker, name in tickers.items():\n",
    "        asset = yf.Ticker(ticker)\n",
    "        end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        start_date = (datetime.today() - timedelta(days=730)).strftime('%Y-%m-%d')\n",
    "        data = asset.history(start=start_date, end=end_date)\n",
    "        data.reset_index(inplace=True)\n",
    "        data['index_name'] = name\n",
    "        all_data.append(data)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "tickers = {\n",
    "    \"^N225\": \"Nikkei 225\",\n",
    "    \"^JPN\": \"Japan Index\"\n",
    "}\n",
    "\n",
    "index_data = fetch_index_data(tickers)\n",
    "index_data.to_csv(\"japan_index_prices.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Market 20-day rolling volatility data saved to NYSE.market.vol.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^JPTBY']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro indicators data saved to US.JPN.macro.indicators.csv\n",
      "Data collection complete!\n",
      "\n",
      "Last 5 days of market volatility:\n",
      "Price      Volatility\n",
      "Ticker               \n",
      "Date                 \n",
      "2024-11-08   0.107980\n",
      "2024-11-11   0.107337\n",
      "2024-11-12   0.108580\n",
      "2024-11-13   0.105402\n",
      "2024-11-14   0.105421\n",
      "\n",
      "Last 5 days of macro indicators:\n",
      "            US_10Y_YIELD  JPN_10Y_YIELD     USD_JPY\n",
      "Date                                               \n",
      "2024-11-08         4.306            NaN  153.179993\n",
      "2024-11-11         4.308            NaN  152.904007\n",
      "2024-11-12         4.432            NaN  153.479996\n",
      "2024-11-13         4.451            NaN  154.654999\n",
      "2024-11-14         4.414            NaN  156.358994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_market_volatility(window=20):  # 20-day rolling volatility by default\n",
    "    # Calculate date range (adding extra days to account for the rolling window)\n",
    "    end_date = datetime.datetime.now()\n",
    "    start_date = end_date - datetime.timedelta(days=730 + window)\n",
    "    \n",
    "    # Fetch NYSE data\n",
    "    nya = yf.download('^NYA', start=start_date, end=end_date)\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    nya['Returns'] = nya['Adj Close'].pct_change()\n",
    "    \n",
    "    # Calculate rolling volatility (annualized)\n",
    "    nya['Volatility'] = nya['Returns'].rolling(window=window).std() * np.sqrt(252)\n",
    "    \n",
    "    # Format data\n",
    "    vol_data = nya[['Volatility']].copy()\n",
    "    vol_data = vol_data.dropna()  # Remove NaN values from the beginning\n",
    "    vol_data.index = vol_data.index.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Save to CSV\n",
    "    vol_data.to_csv('NYSE.market.vol.csv')\n",
    "    print(f\"Market {window}-day rolling volatility data saved to NYSE.market.vol.csv\")\n",
    "    \n",
    "    return vol_data\n",
    "\n",
    "def get_macro_indicators():\n",
    "    # Set up dates\n",
    "    end_date = datetime.datetime.now()\n",
    "    start_date = end_date - datetime.timedelta(days=730)\n",
    "    \n",
    "    # Define tickers for macro data\n",
    "    tickers = {\n",
    "        'US_10Y_YIELD': '^TNX',  # US 10-Year Treasury Yield\n",
    "        'JPN_10Y_YIELD': '^JPTBY',  # Japan 10-Year Bond Yield\n",
    "        'USD_JPY': 'JPY=X'  # USD/JPY Exchange Rate\n",
    "    }\n",
    "    \n",
    "    # Initialize empty DataFrame\n",
    "    macro_data = pd.DataFrame()\n",
    "    \n",
    "    # Fetch data for each indicator\n",
    "    for name, ticker in tickers.items():\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date)['Close']\n",
    "            macro_data[name] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {name}: {e}\")\n",
    "    \n",
    "    # Clean and format data\n",
    "    macro_data = macro_data.fillna(method='ffill')\n",
    "    macro_data.index = macro_data.index.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Save to CSV\n",
    "    macro_data.to_csv('US.JPN.macro.indicators.csv')\n",
    "    print(\"Macro indicators data saved to US.JPN.macro.indicators.csv\")\n",
    "    \n",
    "    return macro_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting data collection...\")\n",
    "    vol_data = get_market_volatility()\n",
    "    macro_data = get_macro_indicators()\n",
    "    print(\"Data collection complete!\")\n",
    "    \n",
    "    # Print the last 5 days of data as a sample\n",
    "    print(\"\\nLast 5 days of market volatility:\")\n",
    "    print(vol_data.tail())\n",
    "    print(\"\\nLast 5 days of macro indicators:\")\n",
    "    print(macro_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting earthquake data collection for M7.0+...\n",
      "Fetching major earthquake data (M7.0+)...\n",
      "\n",
      "Data saved to Japan_major_earthquakes_last_730_days.csv\n",
      "\n",
      "Last 5 major earthquakes (M7.0+):\n",
      "        date  magnitude                                  place\n",
      "1 2024-01-01        7.5  2024 Noto Peninsula, Japan Earthquake\n",
      "0 2024-08-08        7.1   2024 Hyuganada Sea, Japan Earthquake\n",
      "\n",
      "Data collection complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_major_earthquakes_japan():\n",
    "    # Calculate date range for the last 2 years (730 days)\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=730)\n",
    "    \n",
    "    # Fetch earthquake data from the USGS API\n",
    "    print(\"Fetching major earthquake data (M7.0+)...\")\n",
    "    base_url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "    \n",
    "    params = {\n",
    "        'format': 'geojson',\n",
    "        'starttime': start_date.strftime('%Y-%m-%d'),\n",
    "        'endtime': end_date.strftime('%Y-%m-%d'),\n",
    "        'minlatitude': 30,   # Latitude range for Japan\n",
    "        'maxlatitude': 46,\n",
    "        'minlongitude': 129, # Longitude range for Japan\n",
    "        'maxlongitude': 146,\n",
    "        'minmagnitude': 7.0  # Only consider major earthquakes (M7.0 and above)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API returned status code {response.status_code}\")\n",
    "        \n",
    "        eq_data = response.json()\n",
    "        \n",
    "        earthquakes = []\n",
    "        for feature in eq_data['features']:\n",
    "            eq = {\n",
    "                'date': datetime.fromtimestamp(feature['properties']['time'] / 1000).strftime('%Y-%m-%d'),\n",
    "                'magnitude': feature['properties']['mag'],\n",
    "                'place': feature['properties']['place']\n",
    "            }\n",
    "            earthquakes.append(eq)\n",
    "        \n",
    "        # Convert the earthquake data into a DataFrame\n",
    "        eq_df = pd.DataFrame(earthquakes)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching earthquake data: {e}\")\n",
    "        eq_df = pd.DataFrame(columns=['date', 'magnitude', 'place'])\n",
    "    \n",
    "    # Format and clean the DataFrame\n",
    "    eq_df['date'] = pd.to_datetime(eq_df['date'])\n",
    "    eq_df = eq_df.sort_values(by='date')\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = 'Japan_major_earthquakes_last_730_days.csv'\n",
    "    eq_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nData saved to {output_file}\")\n",
    "    print(\"\\nLast 5 major earthquakes (M7.0+):\")\n",
    "    print(eq_df.tail())\n",
    "    \n",
    "    return eq_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting earthquake data collection for M7.0+...\")\n",
    "    earthquake_data = get_major_earthquakes_japan()\n",
    "    print(\"\\nData collection complete!\")\n",
    "\n",
    "## This came out as only 2 observations, thus we left it alone. Key for the poster to talk about how overcame this issue.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
